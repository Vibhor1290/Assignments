{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103deb64-2802-4a7f-a71f-1455b05e080f",
   "metadata": {},
   "source": [
    "# Introduction to ML-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b193c6-d2f0-4dce-a9e0-7d19c4932f38",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7204c5c-a76b-4741-aacd-2af53a80a20b",
   "metadata": {},
   "source": [
    "Overfitting: This is a situation when the training data accuracy is very high and the accuracy of the test data gets very low.\n",
    "\n",
    "Example: Training Accuracy - 95% and Test Accuracy - 60%\n",
    "\n",
    "Underfitting: When the training data accuracy initially is very low and the accuracy of the test data gets further lower.\n",
    "\n",
    "Example: Training Accuracy - 60% and Test Accuracy - 35%\n",
    "\n",
    "To overcome these problems, we introduce third type of dataset(validation dataset) in order to achieve a generalised model. Tnis dataset works on performing modifications in the training dataset so that the training and test accuracy becomes close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25418c96-ebf8-46c1-b7a9-d61781731736",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "raw",
   "id": "26b95bee-3ce2-42c7-b410-0a27b7f76826",
   "metadata": {},
   "source": [
    "There are various methods to reduce overfitting:\n",
    "    \n",
    "    1. Using models with less parameters that are less likely to fit noise in training data.\n",
    "    \n",
    "    2. Removing all those nodes from decision tree that have less importance.\n",
    "    \n",
    "    3. Stopping the training process if the performance on validation set shows no improvement.\n",
    "    \n",
    "    4. Using Principal Component Analysis (PCA) to reduce the number of features in order to remove noise and irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481fcb92-47f0-4e20-a871-0acc70325fa0",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0da0518-ad5d-4442-a38a-72896f0be0bc",
   "metadata": {},
   "source": [
    "Bias refers to the error introduced by approximating a real-world problem, which may be complex, by a simplified model.\n",
    "\n",
    "Variance refers to the error introduced by the model's sensitivity due to small fluctuations in training data.\n",
    "\n",
    "Both bias and variance are inversely proportional.\n",
    "\n",
    "In case of Underfitting, we have high Bias and low Variance. While in Overfitting, we have low Bias and high Variance. Our aim is to create such a model that minimizes both bias and variance. To achieve such model, we use different techniques like ensembling, regularization, feature selection,etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea943325-2e63-4c7a-aaf2-09b2000783a5",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9710fea-b811-4488-8fed-69f2669cb2f0",
   "metadata": {},
   "source": [
    "To detect overfitting and underfitting, we use following techniques:\n",
    "    \n",
    "    1. Plotting Curves: Visualize the training and validation errors against the number of training trials and look for the trend.\n",
    "    \n",
    "If we observe high error in both training and validation set, it represents underfitting.\n",
    "\n",
    "If we observe low error in training but high error in validation set, it represents overfitting.\n",
    "\n",
    "    2. Cross-Validation: We use K-fold technique to find the best accuracy.\n",
    "    \n",
    "If we observe poor model performance in all folds, it represent underfitting.\n",
    "\n",
    "If we observe high variance with good performance on some folds (training data) and poor performance on others (validation data), it denotes overfitting.\n",
    "\n",
    "    3. Performance Metrics (Like precision,recall,F-1 score,etc.)\n",
    "    \n",
    "If we observe poor performance on both training and validation data, it shows underfitting.\n",
    "\n",
    "If we observe good performance in training data but poor in validation, it shows overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c019b7-abfa-40b2-bc02-82910926ede1",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c976a1f1-f420-4f77-b6e7-56627172f1cf",
   "metadata": {},
   "source": [
    "Bias and variance in machine learning helps us in understanding the sources of errors in predictive models.\n",
    "\n",
    "Models with high bias are usually underfitting.\n",
    "\n",
    "Example:\n",
    "\n",
    "Linear Regression on Non-linear Data (if relation b/w features is non-linear and we use linear regression, we will encounter biasness.)\n",
    "\n",
    "Decision Trees with High Pruning (if we excessively prune the decision tree with simple data, it might not capture underlying data properly.)\n",
    "\n",
    "PERFORMANCE: High error in both training and testing data\n",
    "\n",
    "Models with high variance are usually overfitting.\n",
    "\n",
    "Example:\n",
    "\n",
    "Decision Trees with Low Pruning (creating a decision tree with lots of branches can perfectly fit training data but will perform poorly on unseen data.)\n",
    "\n",
    "High-Degree Polynomial Regression (Using a high-degree polynomial to fit data can cause model to follow training data very closely but fail while generalizing new data.)\n",
    "\n",
    "PERFORMANCE: Low error in training but high error in testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b9815-24a2-46f1-8d14-74e2ba645755",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1e9563d-eb18-405d-9cb2-655a8f2d77a5",
   "metadata": {},
   "source": [
    "Regularization is a technique which is used to prevent model overfitting by adding a penalty term to the loss function, thereby not allowing the model from giving too much importance to individual features or coefficients.\n",
    "\n",
    "There are 3 types of regularization used:\n",
    "\n",
    "1. Lasso Regularization(L1 Regularization)\n",
    "\n",
    "Lasso regularization is used for feature selection. It simply puts the weight of those feature approximately to zero, which do not contribute in overall accuracy of the model. \n",
    "\n",
    "2. Ridge Regularization(L2 Regularization)\n",
    "\n",
    "Ridge regression adds the 'squared magnitude' of coefficient as a penalty term to the loss function.\n",
    "\n",
    "3. Elastic Net Regularization(L1 and L2 Regularization)\n",
    "\n",
    "This is a combination of both L1 and L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61264ca-ab47-4c75-8510-b70091fa4c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
