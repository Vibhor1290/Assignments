{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e591efaf-e31c-4e18-bcaf-af1a11c0e0d4",
   "metadata": {},
   "source": [
    "Q1. What is Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4642bab-f1ae-4307-b10f-7cb7d4992875",
   "metadata": {},
   "source": [
    "Random Forest is an ensemble technique specifically designed for regression tasks, which combines the predictions of multiple decision trees to produce more accurate and stable prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4cf04-32f4-489e-93bc-d3ee7881f957",
   "metadata": {},
   "source": [
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57868664-d827-40af-ab4e-da6e586cee8a",
   "metadata": {},
   "source": [
    "There are various paramters that can help reduce the overfitting chances:\n",
    "    \n",
    "1. We can controls how deep we want our decision tree to be. Less depth of tree will result in lower risk of overfiting.\n",
    "\n",
    "2. We can also decide how many number of decision trees will be there in each layer. This arameter again solves the problem of overfitting up to a great extent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf6bf6-b73f-47b8-93c2-4fb6422906bb",
   "metadata": {},
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75e114cf-a191-4bb4-abd3-e8a488b3337f",
   "metadata": {},
   "source": [
    "The calculation of prediction is very simple and straigh forwarded. Once we get the output from different models, we use simple formula of average to find out the overall accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "435d73e9-1622-440a-820b-172a465c6c6b",
   "metadata": {},
   "source": [
    "This averaging process reduces chances of overfitting and enhances the generalization ability of the model. Due to these abilities, Random Forest produces more accurate and stable predictions as compared to an individual decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff04db-9b1d-4e1d-bdc1-4351ef8ae2ea",
   "metadata": {},
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a2fbdfd-1fc1-46ac-9b7f-6bd6befb494c",
   "metadata": {},
   "source": [
    "There are a number of hyperparameters used in Random Forest Regressor.\n",
    "\n",
    "n_estimators=100 (defines the number of decision tree used)\n",
    "\n",
    "criterion='squared_error' (function to measure the quality of split)\n",
    "\n",
    "max_depth=None, (how many layers we want in our decision tree)\n",
    "\n",
    "min_samples_split=2, (number of samples required to split an internal node)\n",
    "\n",
    "max_features=1.0, (number of features to consider when looking for the best split)\n",
    "\n",
    "and many more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03119ef8-35cd-4816-a6bb-403dd2c0ada5",
   "metadata": {},
   "source": [
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0088f8c5-c49c-424b-aa5d-8367656d8797",
   "metadata": {},
   "source": [
    "On the basis od structure:\n",
    "    \n",
    "    Decision Tree Regressor (there is only a single decision tree)\n",
    "    \n",
    "    Random Forest Regressor (there is a combination of multiple decision trees)\n",
    "    \n",
    "On the basis of prediction:\n",
    "    \n",
    "    The prediction in Decision Tree regressor is made by traversing a single tree from root to leaf, following the splits that match feature values of input data.\n",
    "    \n",
    "    The prediction in Random Forest regressor is made by calculating the average of predictions from all the trees in the forest.\n",
    "    \n",
    "Variance-Bias:\n",
    "   \n",
    "    Decision Tree regressor has a low bias but high variance because a single tree is fitting all the training data closely along with capturing the noise as well.\n",
    "    \n",
    "    Random Forest regressor has both low bias and low high variance due to presence of multiple trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a963053-562a-49b9-a6ab-6e3893d8a542",
   "metadata": {},
   "source": [
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ddf0c6f-8b98-4b1a-9312-4ad8af437d47",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "    \n",
    "    High Accuracy\n",
    "    \n",
    "    Reduced overfitting\n",
    "    \n",
    "    Ability to handle high dimesional data\n",
    "    \n",
    "    Less sensitive to noise within the data\n",
    "    \n",
    "Disadvantages:\n",
    "    \n",
    "    Due to mulitple decision trees, training process might be time consuming.\n",
    "    \n",
    "    We might encounter biasness if the data is imbalanced.\n",
    "    \n",
    "    Require more memory resource to store decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8f69a-a8ef-4eb1-a1ef-45cc20a2c0c7",
   "metadata": {},
   "source": [
    "Q7. What is the output of Random Forest Regressor?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ece88af-ad73-4825-87b5-c9cf6a3f3c60",
   "metadata": {},
   "source": [
    "The output of a Random Forest Regressor is simply a continuous numerical value, which is achieved by calculating the average of predictions from multiple decision trees in the ensemble."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ef49cce-bca7-4c49-a9f8-38c480d4d7fd",
   "metadata": {},
   "source": [
    "Example: We have a random forest regressor model having 5 decision trees. We got different accuarcies from each model.\n",
    "\n",
    "DT1: 60%\n",
    "    \n",
    "DT2: 75%\n",
    "    \n",
    "DT3: 90%\n",
    "    \n",
    "DT4: 70%\n",
    "    \n",
    "DT5: 88%\n",
    "\n",
    "Now, to calculate the overall accuracy of the ensemble, we will simply compute the average of all the 5 models.\n",
    "\n",
    "And we get the answer as %76.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536a568-072b-4da9-afba-e4e05347ffad",
   "metadata": {},
   "source": [
    "Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0005664-f634-4543-a0de-a9c9e3b829b8",
   "metadata": {},
   "source": [
    "Yes, Random Forest algorithm can be used for classification tasks as well. When used for classification, it is referred to as a Random Forest Classifier.\n",
    "\n",
    "We will simply use the train data for our multiple decision tree and from each model, we will get a categorical output.\n",
    "\n",
    "Lets say we have 5 models with specific output(either class A or classB):\n",
    "\n",
    "Model1 = class A\n",
    "\n",
    "Model2 = class B\n",
    "\n",
    "Model3 = class A\n",
    "\n",
    "Model4 = class A\n",
    "\n",
    "Model5 = class B"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3306e7e6-d14d-44ea-8fa6-63d98e7efa87",
   "metadata": {},
   "source": [
    "From the outputs of each model, we will apply voting classification and check which output category holds the majority in the result. Here, class A category occurs more than class B so our final output will be class A(or in simple words, the new data will belong to class A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f08069-f6d8-44f4-9863-8560ce1e8bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
