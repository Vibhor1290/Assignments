{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c77a45-1c63-4ad0-a06c-c7160615be90",
   "metadata": {},
   "source": [
    "Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "279558a9-de19-4a91-bfac-074f8db80867",
   "metadata": {},
   "source": [
    "A contingency matrix(or confusion matrix) is a table used to evaluate the performance of classification model. It compares predicted class labels with actual class labels for a set of data points."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3860495d-ea9c-400a-81fa-11eb06ea5858",
   "metadata": {},
   "source": [
    "It mainly holds 4 values:\n",
    "    \n",
    "    1. True Positive (Predicted as positive but actually is positive)\n",
    "    \n",
    "    2. True Negative (Predicted as negative but actually is negative)\n",
    "    \n",
    "    3. False Positive (Predicted as positive but actually is negative)\n",
    "    \n",
    "    4. False Negative (Predicted as negative but actually is positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b26b1e-40b4-4ea8-bda1-7e9d2f2d034f",
   "metadata": {},
   "source": [
    "Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in certain situations?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1d1ba07-3c68-43d2-b506-75ea5a931d33",
   "metadata": {},
   "source": [
    "A pair confusion matrix is a specialized version of confusion matrix used for binary classification tasks where there are two classes(positive and negative). It differs from a regular confusion matrix because it mainly focuses on the performance of binary classifier in distinguishing between pairs of classes rather than all classes in a multi-class classification problem.\n",
    "\n",
    "Pair confusion matrices might be useful in below mentioned situations:\n",
    "\n",
    "1. When one class is much more prevalent than the other, a regular confusion matrix might not provide a clear view of the classifier's performance on the minority class. To deal such cases, pair confusion matrix helps in focusing on the specific class comparison of interest.\n",
    "\n",
    "2. When we are specifically interested in the performance of a classifier in distinguishing between two specific classes, a pair confusion matrix provides a concise summary of relevant metrics.\n",
    "\n",
    "3. In applications where decisions need to be made based on the classifier performance on a specific pair of classes(like fraud detection or medical diagnosis), a pair confusion matrix can help in evaluating the classifier's effectiveness for that decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72541a3-bb31-4a39-8f20-59dfe7543eae",
   "metadata": {},
   "source": [
    "Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically used to evaluate the performance of language models?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d054e995-85d5-4621-8818-4c3c0df214ed",
   "metadata": {},
   "source": [
    "In natural language processing, extrinsic evaluation measures evaluates the performance of language models in context of specific downstream tasks or applications. These tasks can range from sentiment analysis and machine translation to named entity recognition and text classification.\n",
    "\n",
    "1. Language models are usually trained on large datasets using unsupervised/semi-supervised learning techniques. However, the objective of these models is to perform well on real-world tasks that require understanding and processing natural language.\n",
    "\n",
    "2. Evaluation of language models often includes fine-tuning or transfer learning where the pre-trained models are fine-tuned on task-specific data or are used as feature extractors for downstream tasks.\n",
    "\n",
    "3. The results of extrinsic evaluation are often used for benchmarking different language models or comparing the performance of models trained using different techniques or architectures. This helps in advancing the state-of-the-art in NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329889a9-c92d-4935-b4cc-a1059ef82b3b",
   "metadata": {},
   "source": [
    "Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an extrinsic measure?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93727be2-d01b-4028-baa6-44f99bb6f6d9",
   "metadata": {},
   "source": [
    "Intrinsic measures refers to those evaluation metrics that calculates the performance of a model on the basis of its internal characteristics or how perfectly it fits the training data. These measures are typically used during model development and experimentation phase in order to understand the model's behavior, capabilities, and limitations.\n",
    "\n",
    "1. Intrinsic measure focuses on internal characteristics of the model like accuracy, loss function, word error rate, convergence speed, etc. While extrinsic measures focuses on the model performance in completing specific tasks or solving real-world problems.\n",
    "\n",
    "2. Intrinsic measur is used during model development, hyperparameter tuning, and validation to calculate the model fitness to the training data. On the other hand, extrinsic measures are used to evaluate the model performance in practical applications or downstream tasks that require processing natural language, images, audio, etc.\n",
    "\n",
    "3. Intrinsic measures calculates the general aspects of the model's performance like ability to learn patterns, handle noise, avoid overfitting, etc. While extrinsic measures focuses on finding the model's performance in specific tasks relevant to the real world application domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4ff52-8551-4a48-8891-55c9bf012179",
   "metadata": {},
   "source": [
    "Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify strengths and weaknesses of a model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b54e152-f117-42bb-b962-4a784062341b",
   "metadata": {},
   "source": [
    "The main aim of confusion matrix in ML is to find out the overall accuracy or performance of the model. There are 4 values that we find out from confusion matrix.\n",
    "\n",
    "    1. True Positive (Predicted as positive but actually is positive)\n",
    "    \n",
    "    2. True Negative (Predicted as negative but actually is negative)\n",
    "    \n",
    "    3. False Positive (Predicted as positive but actually is negative)\n",
    "    \n",
    "    4. False Negative (Predicted as negative but actually is positive)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a1e4526-db06-4a29-b242-c1a878e54882",
   "metadata": {},
   "source": [
    "Using these values, we can evaluate various metrics like precision, recall, f1-score, accuracy, etc.\n",
    "\n",
    "Accuracy: (TP + TP)/(TP + TN + FP + FN)\n",
    "\n",
    "Precision: TP/(TP + FP)\n",
    "\n",
    "Recall: TP/(TP + FN)\n",
    "\n",
    "F1_Score = (2*P*R)/P+R"
   ]
  },
  {
   "cell_type": "raw",
   "id": "150ae47f-6994-4648-bdd3-bd1f2b507488",
   "metadata": {},
   "source": [
    "CONCLUSION:\n",
    "    High accuracy indicates overall good performance but may not tell us the complete information, especially in imbalanced datasets.\n",
    "    \n",
    "    High precision means low false positive rate, which is important in applications where false positives are costly.\n",
    "    \n",
    "    High recall shows low false negative rate, which is crucial in applications where missing positives is problematic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e5de8a-f90d-4d40-944c-295377cbd240",
   "metadata": {},
   "source": [
    "Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised learning algorithms, and how can they be interpreted?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d04d0937-5237-4484-800c-6ed1f13eda5a",
   "metadata": {},
   "source": [
    "Some of the common intrinsic measures used to evaluate the performance of unsupervised learning algorithms include:\n",
    "\n",
    "Silhouette Score: This measure tell us how much similar an object is to its own cluster as compared to other clusters. A high silhouette score shows that the object is very much similar to its own cluster and poorly to its neighboring clusters. It ranges from -1 to 1, where a score closer to 1 indicates better clustering.\n",
    "\n",
    "Davies-Bouldin Index: This index measures the average similarity between each cluster and its most similar cluster, where similarity is defined in terms of both intra-cluster and inter-cluster distances. A lower DBI indicates better clustering, with 0 being the best possible score.\n",
    "\n",
    "Dunn Index: This index evaluates the compactness of clusters relative to the separation between clusters. A higher Dunn index suggests better clustering, with larger values indicating well-separated and compact clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d72209e-72f1-439a-a7d6-c87278cd38bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
